# AUTOGENERATED! DO NOT EDIT! File to edit: data.ipynb (unless otherwise specified).

__all__ = ['torch2np', 'denorm', 'ImgFolderPipeline', 'TFRecordPipeline', 'SubsetSampler', 'SubsetDataloader',
           'ImgCSVDataset', 'SubsetSampler', 'SubsetDataloader', 'DaliDataloader']

# Cell
import copy
import random
import shutil
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import nvidia.dali.ops as ops
import nvidia.dali.tfrecord as tfrec
import nvidia.dali.types as types
import pandas as pd
import torch
import torch.utils.data as data
import torchvision.transforms as transforms
from IPython.core.debugger import set_trace
from joblib import Parallel, delayed
from nvidia.dali.pipeline import Pipeline
from nvidia.dali.plugin.pytorch import DALIGenericIterator
from PIL import Image
from tqdm.notebook import tqdm

# Cell
def torch2np(img): return img.permute(1,2,0).detach().cpu().numpy()

# Cell
def denorm(img): return (img*np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])).clip(0, 1)

# Cell
class ImgFolderPipeline(Pipeline):
    def __init__(self, dir_imgs, batch_size, num_workers, device_id=0):
        super().__init__(batch_size, num_workers, device_id)
        # Use FileReader to read images and get labels from class folder
        self.input = ops.FileReader(file_root=dir_imgs,
                                    random_shuffle=True)

        # Attempt to decode on gpu
        self.decode = ops.ImageDecoder(device='mixed',
                                       output_type=types.RGB)

        # This has the important action of transposing channel from last to 2nd dimension
        # Note that normalization is done WRT raw uint8 values (so they are [0, 255])
        self.cmnp = ops.CropMirrorNormalize(device='gpu',
                                            output_dtype=types.FLOAT,
                                            output_layout=types.NCHW,
                                            image_type=types.RGB,
                                            mean=[124, 116, 104],
                                            std= [ 58, 57,  57])

    def define_graph(self):
        imgs, _ = self.input()
        imgs = self.decode(imgs) # Images are decoded on gpu
        imgs = self.cmnp(imgs)   # This also converts from NHWC -> NCHW
        return (imgs)

# Cell
class TFRecordPipeline(Pipeline):
    def __init__(self, file_tfrecord, batch_size, num_workers, device_id=0):
        super().__init__(batch_size, num_workers, device_id)
        # Use FileReader to read images and get labels from class folder
        self.input = ops.TFRecordReader(path=file_tfrecord.as_posix(),
                                        index_path=(file_tfrecord.parent/(file_tfrecord.stem + '.idx')).as_posix(),
                                        features={'encoded': tfrec.FixedLenFeature((), tfrec.string, "")})

        # Attempt to decode on gpu
        self.decode = ops.ImageDecoder(device='mixed',
                                       output_type=types.RGB)

        # This has the important action of transposing channel from last to 2nd dimension
        # Note that normalization is done WRT raw uint8 values (so they are [0, 255])
        self.cmnp = ops.CropMirrorNormalize(device='gpu',
                                            output_dtype=types.FLOAT,
                                            output_layout=types.NCHW,
                                            image_type=types.RGB,
                                            mean=[124, 116, 104],
                                            std= [ 58, 57,  57])

    def define_graph(self):
        imgs = self.input(name="Reader")['encoded']
        imgs = self.decode(imgs) # Images are decoded on gpu
        imgs = self.cmnp(imgs)   # This also converts from NHWC -> NCHW
        return (imgs)

# Cell
class SubsetSampler(data.Sampler):
    def __init__(self, data_source, num_samples=None):
        self.data_source = data_source
        self.num_samples = num_samples if num_samples is not None else len(data_source)

    def __iter__(self):
        n = len(self.data_source)
        return iter(torch.randperm(n)[:self.num_samples].tolist())

    def __len__(self):
        return self.num_samples

# Cell
class SubsetDataloader(data.DataLoader):
    def __init__(self, dataset, num_samples=None, **kwargs):
        super().__init__(dataset, sampler=SubsetSampler(dataset, num_samples), **kwargs)

# Cell
class ImgCSVDataset(data.Dataset):
    def __init__(self, dir_imgs, file_csv, tfms=None):
        self.dir_imgs = dir_imgs
        self.tfms = tfms
        self.df = pd.read_csv(file_csv)

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        img = Image.open(self.dir_imgs/self.df.loc[idx, 'name']).convert('RGB')

        if self.tfms is not None:
            img = self.tfms(img)

        return img, copy.deepcopy(img)

# Cell
class SubsetSampler(data.Sampler):
    def __init__(self, data_source, num_samples=None):
        self.data_source = data_source
        self.num_samples = num_samples if num_samples is not None else len(data_source)

    def __iter__(self):
        n = len(self.data_source)
        return iter(torch.randperm(n)[:self.num_samples].tolist())

    def __len__(self):
        return self.num_samples

# Cell
class SubsetDataloader(data.DataLoader):
    def __init__(self, dataset, num_samples=None, **kwargs):
        super().__init__(dataset, sampler=SubsetSampler(dataset, num_samples), **kwargs)

# Cell
class DaliDataloader():
    def __init__(self, pipeline, num_samples):
        self.pipeline = pipeline
        self.num_samples = num_samples

        self.pipeline.build()

    def __iter__(self):
        self.di = DALIGenericIterator(self.pipeline, ['img'], self.num_samples)
        return self

    def __next__(self):
        img = next(self.di)[0]['img']
        return img, copy.deepcopy(img)